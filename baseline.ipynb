{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "The baseline model\n",
    "from  http://cdn2.jianshu.io/p/ed4b49c2d16b\n",
    "https://blog.floydhub.com/colorizing-b&w-photos-with-neural-networks/\n",
    "the input images are 256x256\n",
    "'''\n",
    "from keras.layers import Conv2D, Conv2DTranspose, UpSampling2D\n",
    "from keras.layers import Activation, Dense, Dropout, Flatten, InputLayer\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "\n",
    "from skimage.color import rgb2lab, lab2rgb, rgb2gray\n",
    "from skimage.io import imsave\n",
    "from skimage.transform import resize\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import tensorflow as tf\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 256, 256, 3)\n",
      "(256, 256, 3)\n"
     ]
    }
   ],
   "source": [
    "# Get images\n",
    "#resize(image, output_shape)\n",
    "X =[]\n",
    "#./Mask_RCNN/images\n",
    "for filename in os.listdir('./images/small/Train'):\n",
    "    X.append(img_to_array(load_img('./images/small/train/'+filename,target_size=(256,256))))\n",
    "\n",
    "X = np.array(X)\n",
    "print(X.shape)\n",
    "print(X[0].shape)\n",
    "#X = np.array(X,dtype=np.float32)\n",
    "\n",
    "# Set up train and test data\n",
    "split = int(0.95*len(X))\n",
    "Xtrain = X[:split]\n",
    "Xtrain = 1.0/255*Xtrain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#design the neural model\n",
    "model = Sequential()\n",
    "model.add(InputLayer(input_shape=(256, 256, 1)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding='same', strides=2))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu', padding='same', strides=2))\n",
    "model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(256, (3, 3), activation='relu', padding='same', strides=2))\n",
    "model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "model.add(UpSampling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "model.add(UpSampling2D((2, 2)))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(2, (3, 3), activation='tanh', padding='same'))\n",
    "model.add(UpSampling2D((2, 2)))\n",
    "# finish model\n",
    "model.compile(optimizer='rmsprop', loss='mse')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "10/10 [==============================] - 123s 12s/step - loss: 0.9165\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x11b8efcc0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Image transformer\n",
    "datagen = ImageDataGenerator(\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        rotation_range=20,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "\n",
    "# Generate training data\n",
    "#change batch to 50-100\n",
    "#steps_per_epoch=totoal number/batch\n",
    "batch_size = 10\n",
    "#make sure the images will not be the same through iterations\n",
    "def image_a_b_gen(batch_size):\n",
    "    #datagen.flow(Xtrain, batch_size=batch_size)\n",
    "    for batch in datagen.flow(Xtrain, batch_size=batch_size):\n",
    "        lab_batch = rgb2lab(batch)\n",
    "        X_batch = lab_batch[:,:,:,0]\n",
    "        Y_batch = lab_batch[:,:,:,1:] / 128\n",
    "        yield (X_batch.reshape(X_batch.shape+(1,)), Y_batch)\n",
    "\n",
    "# Train model      \n",
    "tensorboard = TensorBoard(log_dir=\"log/baseline/output/first_run\")\n",
    "model.fit_generator(image_a_b_gen(batch_size), callbacks=[tensorboard], epochs=1, steps_per_epoch=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "model_json = model.to_json()\n",
    "with open(\"log/baseline/model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "model.save_weights(\"log/baseline/model.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 436ms/step\n",
      "1.0009868145\n"
     ]
    }
   ],
   "source": [
    "# Test images\n",
    "Xtest = rgb2lab(1.0/255*X[split:])[:,:,:,0]\n",
    "Xtest = Xtest.reshape(Xtest.shape+(1,))\n",
    "Ytest = rgb2lab(1.0/255*X[split:])[:,:,:,1:]\n",
    "Ytest = Ytest / 128\n",
    "print(model.evaluate(Xtest, Ytest, batch_size=batch_size))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Melanie/anaconda3/envs/tensorflow/lib/python3.6/site-packages/skimage/color/colorconv.py:985: UserWarning: Color data out of range: Z < 0 in 52083 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "/Users/Melanie/anaconda3/envs/tensorflow/lib/python3.6/site-packages/skimage/util/dtype.py:122: UserWarning: Possible precision loss when converting from float64 to uint8\n",
      "  .format(dtypeobj_in, dtypeobj_out))\n",
      "/Users/Melanie/anaconda3/envs/tensorflow/lib/python3.6/site-packages/skimage/color/colorconv.py:985: UserWarning: Color data out of range: Z < 0 in 63457 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "/Users/Melanie/anaconda3/envs/tensorflow/lib/python3.6/site-packages/skimage/color/colorconv.py:985: UserWarning: Color data out of range: Z < 0 in 53386 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "/Users/Melanie/anaconda3/envs/tensorflow/lib/python3.6/site-packages/skimage/color/colorconv.py:985: UserWarning: Color data out of range: Z < 0 in 34758 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "/Users/Melanie/anaconda3/envs/tensorflow/lib/python3.6/site-packages/skimage/color/colorconv.py:985: UserWarning: Color data out of range: Z < 0 in 64151 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "/Users/Melanie/anaconda3/envs/tensorflow/lib/python3.6/site-packages/skimage/color/colorconv.py:985: UserWarning: Color data out of range: Z < 0 in 34173 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "/Users/Melanie/anaconda3/envs/tensorflow/lib/python3.6/site-packages/skimage/color/colorconv.py:985: UserWarning: Color data out of range: Z < 0 in 30082 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "/Users/Melanie/anaconda3/envs/tensorflow/lib/python3.6/site-packages/skimage/color/colorconv.py:985: UserWarning: Color data out of range: Z < 0 in 24004 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n"
     ]
    }
   ],
   "source": [
    "#still train data\n",
    "color_me = []\n",
    "#./Mask_RCNN/images/\n",
    "for filename in os.listdir('./images/small/Validate'):\n",
    "    color_me.append(img_to_array(load_img('./images/small/Validate/'+filename,target_size=(256,256))))\n",
    "color_me = np.array(color_me, dtype=float)\n",
    "color_me = rgb2lab(1.0/255*color_me)[:,:,:,0]\n",
    "color_me = color_me.reshape(color_me.shape+(1,))\n",
    "\n",
    "# Test model\n",
    "output = model.predict(color_me)\n",
    "output = output * 128\n",
    "\n",
    "# Output colorizations\n",
    "for i in range(len(output)):\n",
    "    cur = np.zeros((256, 256, 3))\n",
    "    cur[:,:,0] = color_me[i][:,:,0]\n",
    "    cur[:,:,1:] = output[i]\n",
    "    imsave(\"log/baseline/output/img1_\"+str(i)+\".png\", lab2rgb(cur))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
